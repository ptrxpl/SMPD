{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statystyczne metody przetwarzania danych \n",
    "\n",
    "## Laboratorium 4 - algorytm normalizacja, selekcja cech.\n",
    "\n",
    "\n",
    "### Opis\n",
    "Celem laboratorium jest przeprowadzenie normalizacji i selekcji cech.\n",
    "\n",
    "### Termin\n",
    "Zadanie nale偶y wykona tego samego dnia. \n",
    "\n",
    "### System oceniania\n",
    "\n",
    "| Liczba punkt贸w (procentowo) | Ocena |\n",
    "| :----                    | ---: |\n",
    "| [0-50)   | 2   |\n",
    "| [50-60)  | 3   |\n",
    "| [60-70)  | 3.5 |\n",
    "| [70-80)  | 4   |\n",
    "| [80-90)  | 4.5 |\n",
    "| [90-100] | 5   |\n",
    "\n",
    "<u>Punkty ujemne</u>\n",
    "\n",
    "* `ocena - 0.5` je偶eli zadanie wysano po laboratorium, ale < 7 dni; \n",
    "* `ocena - 1` je偶eli zadanie wysano w terminie pomidzy 7 a 14 dni;\n",
    "* `ocena - 1.5` je偶eli zadanie wysano po upywie 14 dni, ale przed ostatnim laboratorium;\n",
    "* `ocena = 2` je偶eli zadanie wysano po ostatnim laboratorium.\n",
    "\n",
    "<u>Uwaga:</u>\n",
    "\n",
    "Niedopuszczalne jest dzielenie si notatnikiem (plik `.ipynb`) z innymi studentami ani udostpnianie go w Internecie. Ka偶dy student powinien pobra notatnik samodzielnie z platformy WIKAMP.\n",
    "Wysyajc zadanie potwierdasz, 偶e wykonae je samodzielnie i jest to Twoja indywidualna praca a materia przedstawiony w tej pracy jest dla Ciebie zrozumiay. Prace bardzo podobne albo grupowe bd uznawane za plagiat.\n",
    "\n",
    "\n",
    "### Zbi贸r danych\n",
    "\n",
    "Zbi贸r danych znajduje si w katalogu `dataset/*`. Jest to zmodyfikowany zbi贸r danych znajdujcy si pod adresem: <https://archive.ics.uci.edu/ml/datasets/leaf>.\n",
    "\n",
    "### Przesyanie zada\n",
    "\n",
    "Wszystkie pliki nale偶y spakowa archiwizatorem **zip** i przesa za porednictwem platformy WIKAMP. Poni偶ej oczekiwana zawarto archiwum:\n",
    "\n",
    "```\n",
    "+--  [IMIE.NAZWISKO].zip\n",
    "    +--  Lab04.ipynb\n",
    "    +--  dataset\n",
    "        +--  dataset.npz\n",
    "        +--  ReadMe.pdf\n",
    "```\n",
    "\n",
    "**Pamitaj, wyniki powinny by czytelnie opisane oraz zaprezentowane graficznie (je偶eli jest taka mo偶liwo). Warstwa prezentacji danych to jeden z g贸wnych element贸w wpywajcych na ocen.**\n",
    "\n",
    "Przykad (na podstawie tablicy pomyek):\n",
    "\n",
    "**殴le** (nie wiadomo co jest poni偶ej zaprezentowane, kolumny ani wiersze nie s podpisane, nie wiadomo kt贸re z nich prezentuj predykcje, a kt贸re waciwe etykiety):\n",
    "```\n",
    "array([[2, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 2]])\n",
    "```\n",
    "\n",
    "### Zadanie\n",
    "\n",
    "Nale偶y wykona nastpujce czynnoci w celu realizacji niniejszego zadania:\n",
    "\n",
    "### Normalizacja\n",
    "* Wczytaj dane.\n",
    "* Znormalizuj dane.\n",
    "* Przeprowad藕 eksperyment z zastosowaniem algorytmu kNN lub NM dla danych znormalizowanych oraz bez normalizacji.\n",
    "    * W eksperymencie wybierz minimum 5 klas oraz 10 cech.\n",
    "* Przedstaw por贸wnanie wynik贸w klasyfikacji na danych znormalizowanych i bez normalizacji.\n",
    "* Napisz wnioski.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piotr Klimczak, 1SIiUM2, 239533 / 215275\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('./dataset/dataset.npz', 'rb') as f:\n",
    "    data = np.load(f)\n",
    "    train, test = data['train'], data['test']\n",
    "    \n",
    "columns_name = ['Class','Specimen Number','Eccentricity','Aspect Ratio','Elongation','Solidity',\n",
    "                'Stochastic Convexity','Isoperimetric Factor','Maximal Indentation Depth','Lobedness',\n",
    "                'Average Intensity','Average Contrast','Smoothness','Third moment','Uniformity','Entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizowaie - (x-xmin)/(xmax-xmin)\n",
    "# axis=0 |, axis=1 _\n",
    "# [wiersze, kolumny]\n",
    "\n",
    "train_min = np.min(train, axis=0) #Szukanie minimum ka偶dej kolumny\n",
    "train_max = np.max(train, axis=0) #Szukanie maximum ka偶dej kolumny\n",
    "train_normalized = (train - train_min) / (train_max - train_min) #Normalizowanie danych treningowych\n",
    "train_normalized[:,0] = train[:,0] #Podmienie znormalizowane numery klas na te, co byly\n",
    "\n",
    "#Znormalizuje te偶 dane testowe ALE WYKORZYSTUJC MIN I MAX Z DANYCH TRENINGOWYCH (bo tak trzeba)\n",
    "test_normalized = (test - train_min) / (train_max - train_min) #Normalizowanie danych testowych\n",
    "test_normalized[:,0] = test[:,0] #Podmienie znormalizowane numery klas na te, co byly; [wszystkie wiersze, kolumna 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + normalizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Stochastic Convexity</th>\n",
       "      <th>Isoperimetric Factor</th>\n",
       "      <th>Maximal Indentation Depth</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Average Intensity</th>\n",
       "      <th>Average Contrast</th>\n",
       "      <th>Smoothness</th>\n",
       "      <th>Third moment</th>\n",
       "      <th>Uniformity</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.822817</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.114205</td>\n",
       "      <td>0.021510</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.216215</td>\n",
       "      <td>0.091114</td>\n",
       "      <td>0.094380</td>\n",
       "      <td>0.030993</td>\n",
       "      <td>0.163356</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.810909</td>\n",
       "      <td>0.180505</td>\n",
       "      <td>0.414745</td>\n",
       "      <td>0.177331</td>\n",
       "      <td>0.071034</td>\n",
       "      <td>0.163708</td>\n",
       "      <td>0.065579</td>\n",
       "      <td>0.063462</td>\n",
       "      <td>0.033540</td>\n",
       "      <td>0.137765</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.834726</td>\n",
       "      <td>0.536158</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.025423</td>\n",
       "      <td>0.550790</td>\n",
       "      <td>0.553685</td>\n",
       "      <td>0.378656</td>\n",
       "      <td>0.246772</td>\n",
       "      <td>0.421772</td>\n",
       "      <td>0.886722</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.767267</td>\n",
       "      <td>0.182020</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.077102</td>\n",
       "      <td>0.188813</td>\n",
       "      <td>0.077119</td>\n",
       "      <td>0.079629</td>\n",
       "      <td>0.030980</td>\n",
       "      <td>0.134598</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.457750</td>\n",
       "      <td>0.157810</td>\n",
       "      <td>0.703015</td>\n",
       "      <td>0.500822</td>\n",
       "      <td>0.151979</td>\n",
       "      <td>0.266302</td>\n",
       "      <td>0.120445</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>0.085557</td>\n",
       "      <td>0.312219</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.741376</td>\n",
       "      <td>0.340158</td>\n",
       "      <td>0.249261</td>\n",
       "      <td>0.059936</td>\n",
       "      <td>0.183214</td>\n",
       "      <td>0.428716</td>\n",
       "      <td>0.162708</td>\n",
       "      <td>0.188195</td>\n",
       "      <td>0.085387</td>\n",
       "      <td>0.329034</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.770239</td>\n",
       "      <td>0.386188</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>0.050839</td>\n",
       "      <td>0.229129</td>\n",
       "      <td>0.385119</td>\n",
       "      <td>0.208638</td>\n",
       "      <td>0.188408</td>\n",
       "      <td>0.084388</td>\n",
       "      <td>0.413497</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.533699</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.655226</td>\n",
       "      <td>0.438121</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.264629</td>\n",
       "      <td>0.105414</td>\n",
       "      <td>0.111274</td>\n",
       "      <td>0.030885</td>\n",
       "      <td>0.246515</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.952172</td>\n",
       "      <td>0.777933</td>\n",
       "      <td>0.240784</td>\n",
       "      <td>0.057727</td>\n",
       "      <td>0.663956</td>\n",
       "      <td>0.822874</td>\n",
       "      <td>0.780706</td>\n",
       "      <td>0.990042</td>\n",
       "      <td>0.216042</td>\n",
       "      <td>0.608515</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.399660</td>\n",
       "      <td>0.155492</td>\n",
       "      <td>0.657139</td>\n",
       "      <td>0.410059</td>\n",
       "      <td>0.108593</td>\n",
       "      <td>0.189355</td>\n",
       "      <td>0.077970</td>\n",
       "      <td>0.085160</td>\n",
       "      <td>0.084397</td>\n",
       "      <td>0.295165</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Stochastic Convexity  Isoperimetric Factor  \\\n",
       "0     31.0              0.822817              0.204748   \n",
       "1     31.0              0.810909              0.180505   \n",
       "2     30.0              0.834726              0.536158   \n",
       "3     31.0              0.767267              0.182020   \n",
       "4     11.0              0.457750              0.157810   \n",
       "..     ...                   ...                   ...   \n",
       "270    5.0              0.741376              0.340158   \n",
       "271    5.0              0.770239              0.386188   \n",
       "272   11.0              0.533699              0.220300   \n",
       "273   25.0              0.952172              0.777933   \n",
       "274   11.0              0.399660              0.155492   \n",
       "\n",
       "     Maximal Indentation Depth  Lobedness  Average Intensity  \\\n",
       "0                     0.114205   0.021510           0.091549   \n",
       "1                     0.414745   0.177331           0.071034   \n",
       "2                     0.131375   0.025423           0.550790   \n",
       "3                     0.255600   0.071749           0.077102   \n",
       "4                     0.703015   0.500822           0.151979   \n",
       "..                         ...        ...                ...   \n",
       "270                   0.249261   0.059936           0.183214   \n",
       "271                   0.213592   0.050839           0.229129   \n",
       "272                   0.655226   0.438121           0.121004   \n",
       "273                   0.240784   0.057727           0.663956   \n",
       "274                   0.657139   0.410059           0.108593   \n",
       "\n",
       "     Average Contrast  Smoothness  Third moment  Uniformity   Entropy  \\\n",
       "0            0.216215    0.091114      0.094380    0.030993  0.163356   \n",
       "1            0.163708    0.065579      0.063462    0.033540  0.137765   \n",
       "2            0.553685    0.378656      0.246772    0.421772  0.886722   \n",
       "3            0.188813    0.077119      0.079629    0.030980  0.134598   \n",
       "4            0.266302    0.120445      0.102468    0.085557  0.312219   \n",
       "..                ...         ...           ...         ...       ...   \n",
       "270          0.428716    0.162708      0.188195    0.085387  0.329034   \n",
       "271          0.385119    0.208638      0.188408    0.084388  0.413497   \n",
       "272          0.264629    0.105414      0.111274    0.030885  0.246515   \n",
       "273          0.822874    0.780706      0.990042    0.216042  0.608515   \n",
       "274          0.189355    0.077970      0.085160    0.084397  0.295165   \n",
       "\n",
       "     Klasyfikacja probki  \n",
       "0                    5.0  \n",
       "1                   31.0  \n",
       "2                   30.0  \n",
       "3                    5.0  \n",
       "4                   11.0  \n",
       "..                   ...  \n",
       "270                  5.0  \n",
       "271                  5.0  \n",
       "272                 11.0  \n",
       "273                 25.0  \n",
       "274                 11.0  \n",
       "\n",
       "[275 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 wybranych klas:\n",
    "klasy = [31, 5, 11, 25, 30] \n",
    "#klasy = [29, 5, 8, 4, 31]\n",
    "\n",
    "#cech jest 10\n",
    "#print(np.arange(6,16,1)) = [ 6  7  8  9 10 11 12 13 14 15]\n",
    "wybrane_cechy = np.arange(5,15,1)\n",
    "\n",
    "#Wybieranie klas\n",
    "train_normalized_df = pd.DataFrame(train_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_normalized_df.loc[train_normalized_df['Class'].isin(klasy)] #by wybra klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_normalized_df = pd.DataFrame(test_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_normalized_df.loc[test_normalized_df['Class'].isin(klasy)] #by wybra klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie redniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyj numer klasy\n",
    "\n",
    "#Liczenie odlegoci\n",
    "sum_pow = 0 #init zmiennej do liczenia potgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = kt贸ra klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],12)) #tyle ile probek test. wierszy, 12 bo: klasa - 10 cechy - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest pr贸bek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potgi\n",
    "        \n",
    "        for kolumna in wybrane_cechy: #10 cech \n",
    "            #(sprawdzone na innych, typu 6:16 i one byly duzo gorsze)\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odlegoci \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odlego\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z redniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 11] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano pr贸bk\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:11] = test_class[:, 6:16] #chce cechy\n",
    "#numpy tak naprawd nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Stochastic Convexity','Isoperimetric Factor','Maximal Indentation Depth','Lobedness',\n",
    "                   'Average Intensity','Average Contrast','Smoothness','Third moment','Uniformity','Entropy',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matrix():\n",
    "    y_true = wynik_klasyfikacji['Class']\n",
    "    y_pred = wynik_klasyfikacji['Klasyfikacja probki']\n",
    "    \n",
    "    unique = np.unique([y_pred.to_numpy()]) #w ktorymkolwiek, bo przeciez sa te same klasy tu i tu\n",
    "    \n",
    "    conmat = pd.DataFrame(\n",
    "        confusion_matrix(y_true, y_pred, labels=unique),\n",
    "        index = ['True: {:}'.format(x) for x in unique],\n",
    "        columns = ['Pred: {:}'.format(x) for x in unique]\n",
    "    )\n",
    "    \n",
    "    print(conmat)\n",
    "    \n",
    "def Dokladnosc():\n",
    "    zgodne = 0 #init & czysc zmienna\n",
    "\n",
    "    for i in range(len(wynik_klasyfikacji)):\n",
    "        if ((wynik_klasyfikacji['Class'])[i]  == (wynik_klasyfikacji['Klasyfikacja probki'])[i]): #czy pokrywa si klasyfikacja\n",
    "            zgodne += 1 #je偶eli tak, +1\n",
    "        \n",
    "    acc = zgodne / len(wynik_klasyfikacji)\n",
    "    print(\"\\n\")\n",
    "    print(\"Dokadno: \", acc*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          55           0           0           0           0\n",
      "True: 11.0          0          84           0           0           4\n",
      "True: 25.0          0           0          22          11           0\n",
      "True: 30.0          2           0           0          53           0\n",
      "True: 31.0         32           0           0           0          12\n",
      "\n",
      "\n",
      "Dokadno:  82.18181818181817 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + brak normalizacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Stochastic Convexity</th>\n",
       "      <th>Isoperimetric Factor</th>\n",
       "      <th>Maximal Indentation Depth</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Average Intensity</th>\n",
       "      <th>Average Contrast</th>\n",
       "      <th>Smoothness</th>\n",
       "      <th>Third moment</th>\n",
       "      <th>Uniformity</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.984210</td>\n",
       "      <td>0.196380</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.075247</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.489920</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.973680</td>\n",
       "      <td>0.174290</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>1.227000</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.060688</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.419280</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.994740</td>\n",
       "      <td>0.498360</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>0.168820</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>2.486600</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.935090</td>\n",
       "      <td>0.175670</td>\n",
       "      <td>0.049695</td>\n",
       "      <td>0.449460</td>\n",
       "      <td>0.013721</td>\n",
       "      <td>0.067649</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.410540</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.153610</td>\n",
       "      <td>0.140820</td>\n",
       "      <td>3.609300</td>\n",
       "      <td>0.028638</td>\n",
       "      <td>0.089135</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.900820</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.912196</td>\n",
       "      <td>0.319765</td>\n",
       "      <td>0.048404</td>\n",
       "      <td>0.362463</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.134169</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.947233</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.937718</td>\n",
       "      <td>0.361707</td>\n",
       "      <td>0.041139</td>\n",
       "      <td>0.295472</td>\n",
       "      <td>0.044008</td>\n",
       "      <td>0.122080</td>\n",
       "      <td>0.014654</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>1.180374</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.728558</td>\n",
       "      <td>0.210551</td>\n",
       "      <td>0.131087</td>\n",
       "      <td>3.147546</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>0.088671</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.719461</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.098591</td>\n",
       "      <td>0.718665</td>\n",
       "      <td>0.046677</td>\n",
       "      <td>0.346197</td>\n",
       "      <td>0.130635</td>\n",
       "      <td>0.243460</td>\n",
       "      <td>0.058580</td>\n",
       "      <td>0.025878</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>1.718675</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.610035</td>\n",
       "      <td>0.151498</td>\n",
       "      <td>0.131477</td>\n",
       "      <td>2.940893</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>0.067799</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.853746</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Stochastic Convexity  Isoperimetric Factor  \\\n",
       "0     31.0              0.984210              0.196380   \n",
       "1     31.0              0.973680              0.174290   \n",
       "2     30.0              0.994740              0.498360   \n",
       "3     31.0              0.935090              0.175670   \n",
       "4     11.0              0.661400              0.153610   \n",
       "..     ...                   ...                   ...   \n",
       "270    5.0              0.912196              0.319765   \n",
       "271    5.0              0.937718              0.361707   \n",
       "272   11.0              0.728558              0.210551   \n",
       "273   25.0              1.098591              0.718665   \n",
       "274   11.0              0.610035              0.151498   \n",
       "\n",
       "     Maximal Indentation Depth  Lobedness  Average Intensity  \\\n",
       "0                     0.020897   0.079479           0.016599   \n",
       "1                     0.082108   1.227000           0.012512   \n",
       "2                     0.024394   0.108300           0.108090   \n",
       "3                     0.049695   0.449460           0.013721   \n",
       "4                     0.140820   3.609300           0.028638   \n",
       "..                         ...        ...                ...   \n",
       "270                   0.048404   0.362463           0.034861   \n",
       "271                   0.041139   0.295472           0.044008   \n",
       "272                   0.131087   3.147546           0.022467   \n",
       "273                   0.046677   0.346197           0.130635   \n",
       "274                   0.131477   2.940893           0.019995   \n",
       "\n",
       "     Average Contrast  Smoothness  Third moment  Uniformity   Entropy  \\\n",
       "0            0.075247    0.005630      0.001901    0.000044  0.489920   \n",
       "1            0.060688    0.003670      0.001074    0.000052  0.419280   \n",
       "2            0.168820    0.027709      0.005981    0.001234  2.486600   \n",
       "3            0.067649    0.004556      0.001506    0.000044  0.410540   \n",
       "4            0.089135    0.007882      0.002118    0.000210  0.900820   \n",
       "..                ...         ...           ...         ...       ...   \n",
       "270          0.134169    0.011128      0.004413    0.000210  0.947233   \n",
       "271          0.122080    0.014654      0.004418    0.000207  1.180374   \n",
       "272          0.088671    0.006728      0.002353    0.000044  0.719461   \n",
       "273          0.243460    0.058580      0.025878    0.000607  1.718675   \n",
       "274          0.067799    0.004621      0.001654    0.000207  0.853746   \n",
       "\n",
       "     Klasyfikacja probki  \n",
       "0                   30.0  \n",
       "1                    5.0  \n",
       "2                   30.0  \n",
       "3                    5.0  \n",
       "4                   31.0  \n",
       "..                   ...  \n",
       "270                  5.0  \n",
       "271                  5.0  \n",
       "272                 11.0  \n",
       "273                 25.0  \n",
       "274                 11.0  \n",
       "\n",
       "[275 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wybieranie klas\n",
    "train_df = pd.DataFrame(train, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_df.loc[train_df['Class'].isin(klasy)] #by wybra klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_df = pd.DataFrame(test, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_df.loc[test_df['Class'].isin(klasy)] #by wybra klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie redniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyj numer klasy\n",
    "\n",
    "#Liczenie odlegoci\n",
    "sum_pow = 0 #init zmiennej do liczenia potgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = kt贸ra klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],12)) #tyle ile probek test. wierszy, 12 bo: klasa - 10 cechy - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest pr贸bek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potgi\n",
    "\n",
    "        for kolumna in wybrane_cechy: #10 cech (ostatnie 10 kolumn)\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odlegoci \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odlego\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z redniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 11] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano pr贸bk\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:11] = test_class[:, 6:16] #chce cechy\n",
    "#numpy tak naprawd nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Stochastic Convexity','Isoperimetric Factor','Maximal Indentation Depth','Lobedness',\n",
    "                   'Average Intensity','Average Contrast','Smoothness','Third moment','Uniformity','Entropy',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          51           0           0           4           0\n",
      "True: 11.0          0          66           0           0          22\n",
      "True: 25.0          0           0          33           0           0\n",
      "True: 30.0          0           0           0          55           0\n",
      "True: 31.0         33           0           0          11           0\n",
      "\n",
      "\n",
      "Dokadno:  74.54545454545455 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacja - wnioski\n",
    "Przeprowadzono poprawn normalizacj danych - z zbioru treningowego wyznaczono min i max warto, nastpnie policzono (x-xmin)/(xmax-xmin).\n",
    "\n",
    "To samo zrobiono dla zbioru testowego, wykorzystujc min i max z zbioru treningowego.\n",
    "\n",
    "Wybraem pierwsze 10 cech z podanego datasetu.\n",
    "\n",
    "[ReadMe.pdf]: shape (attributes 3 to 9) and texture (attributes 10 to 16) - uznaem, 偶e shape jest wa偶niejsze\n",
    "\n",
    "Wyniki:\n",
    "- dla klas [31, 5, 11, 25, 30] osignito **82.18% po** oraz **74.55% przed** normalizacj\n",
    "\n",
    "Jak wida, normalizacja podniosa poziom dopasowania pr贸bek testowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selekcja cech\n",
    "* Przeprowad藕 selekcj cech za pomoc metod poznanych na wykadzie (np. z zastosowaniem wsp贸czynnika Fishera)\n",
    "    * Wybierz 2-5 cech (ze zbioru 10 cech wybranych w poprzednim eksperymencie) i opisz dlaczego je wybrae.\n",
    "* Przeprowad藕 klasyfikacj na wybranych cechach.\n",
    "* Por贸wnaj wyniki klasyfikacji:\n",
    "    * dla 10 cech bez normalizacji,\n",
    "    * dla 10 cech z normalizacj,\n",
    "    * dla 2-5 cech bez normalizacji,\n",
    "    * dla 2-5 cech z normalizacj.\n",
    "* Opisz wyniki i napisz wnioski.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique, count\n",
      "[(10.0, 7), (5.0, 5), (3.0, 4), (4.0, 3), (8.0, 3), (6.0, 3), (2.0, 2)]\n"
     ]
    }
   ],
   "source": [
    "#Wybieranie klas i obliczanie macierzy kowariancji\n",
    "train_df = pd.DataFrame(train_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_df.loc[train_df['Class'].isin(klasy)] #by wybra klasy, do redniej\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "train_cov = list() #lista do kt贸rej bdziemy dodawa wyniki\n",
    "\n",
    "for x in range(len(klasy)): #tyle, ile jest klas\n",
    "    train_class_pojedyncza = train_df.loc[train_df['Class'].isin([klasy[x]])] #by wybra klas konkretn\n",
    "    train_class_pojedyncza_numpy = train_class_pojedyncza.to_numpy() #z powrotem do numpy arraya\n",
    "    train_cov.append(np.cov(train_class_pojedyncza_numpy[:, wybrane_cechy].T)) #<- WYBIERANIE CECH\n",
    "    #m. kowariancji liczona por贸d 10 cech (od 6 do 15 kolumny), transponowane by pasowa rozmiar\n",
    "    \n",
    "#Liczenie redniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #[5, 16], [wiersze ile klas, kolumny 16]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    \n",
    "#Liczenie Fishera\n",
    "fisher = np.empty((10,2)) #10 wierszy, 2 kolumny - 10 cech, 1 warto policzona, 2 jaka cecha byla\n",
    "fisher_all = list()\n",
    "\n",
    "#[klasa,klasanext] = [01,02,03,04 | 12,13,14 | 23,24 | 34] = 10 razy, 10 roznych polaczen miedzy klasami\n",
    "for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "\n",
    "    for klasanext in range(klasa + 1, len(klasy)): #tyle, ile jest klas, ale +1;\n",
    "    #nawet jak klasa = 4, to ten for sie po prostu nie wykona\n",
    "           \n",
    "        for cecha in range(10): #tyle, ile jest cech (10)\n",
    "            fisher[cecha,0] = abs(mean[klasa, cecha+1] - mean[klasanext, cecha+1]) / (np.sqrt(train_cov[klasa][cecha,cecha]) + np.sqrt(train_cov[klasanext][cecha,cecha]))\n",
    "            #mean[wiersze-5klas, 16kolumn]; \n",
    "            #abs(mean[klasa0,cecha+1]) - mean[klasa1,cecha+1], potem we藕 lad dlatego [cecha,cecha] - idzie po glownej przekatnej\n",
    "            #cecha+1 偶eby omin kolumn 0 z klasami\n",
    "            fisher[cecha,1] = cecha+1 #jaka cecha?\n",
    "                \n",
    "        fisher_all.append(fisher[fisher[:,0].argsort()[::-1]]) #posortowanego fishera przypisz do ogolnej listy\n",
    "        #fisher[ fisher[wszystkie-wiersze,kolumna0-policzonecechy].argsort() ]\n",
    "        #[::-1] - start:stop:step - wszystkie:wszystkie:od konca, bo -1 to ostatni element w arrayu ogolnie, jak by wywolywac\n",
    "            \n",
    "result = [l[:3] for l in fisher_all] #we藕 po kolei ka偶d tabel z fisher_all i poka偶 3 pierwsze\n",
    "\n",
    "unique, count = np.unique(result, return_counts=True) #pokaz unikatowe wartosci oraz ile razy sie pojawily\n",
    "\n",
    "print(\"unique, count\")\n",
    "print(sorted(set(zip(unique,count)), key = lambda x: x[1], reverse=True)[:7])\n",
    "#lacze zipem unique i count, setem ustawiam (by dalo sie to 'pokazac'), sortuje po kolumnie 1, odwracam, pobieram pierwsze :7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + normalizacja + 3 wybrane cechy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.744569</td>\n",
       "      <td>0.489485</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.071034</td>\n",
       "      <td>0.631097</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.550790</td>\n",
       "      <td>0.748358</td>\n",
       "      <td>0.025252</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.077102</td>\n",
       "      <td>0.675440</td>\n",
       "      <td>0.487136</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.151979</td>\n",
       "      <td>0.168926</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.183214</td>\n",
       "      <td>0.706166</td>\n",
       "      <td>0.082252</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.229129</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.060216</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.315646</td>\n",
       "      <td>0.034811</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.663956</td>\n",
       "      <td>0.887008</td>\n",
       "      <td>0.064020</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.108593</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Lobedness  Elongation  Eccentricity  Klasyfikacja probki\n",
       "0     31.0   0.091549    0.744569      0.489485                 31.0\n",
       "1     31.0   0.071034    0.631097      0.476341                 31.0\n",
       "2     30.0   0.550790    0.748358      0.025252                 25.0\n",
       "3     31.0   0.077102    0.675440      0.487136                 31.0\n",
       "4     11.0   0.151979    0.168926      0.023431                 11.0\n",
       "..     ...        ...         ...           ...                  ...\n",
       "270    5.0   0.183214    0.706166      0.082252                  5.0\n",
       "271    5.0   0.229129    0.690647      0.060216                  5.0\n",
       "272   11.0   0.121004    0.315646      0.034811                 11.0\n",
       "273   25.0   0.663956    0.887008      0.064020                 25.0\n",
       "274   11.0   0.108593    0.035960      0.021973                 11.0\n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns_name = ['Class','Specimen Number','Eccentricity','Aspect Ratio','Elongation','Solidity',\n",
    "#                'Stochastic Convexity','Isoperimetric Factor','Maximal Indentation Depth','Lobedness',\n",
    "#                'Average Intensity','Average Contrast','Smoothness','Third moment','Uniformity','Entropy']\n",
    "\n",
    "#wybrane cechy z powyzej, narazie top3\n",
    "wybrane_cechy = [10,5,3] \n",
    "\n",
    "#Wybieranie klas\n",
    "train_normalized_df = pd.DataFrame(train_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_normalized_df.loc[train_normalized_df['Class'].isin(klasy)] #by wybra klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_normalized_df = pd.DataFrame(test_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_normalized_df.loc[test_normalized_df['Class'].isin(klasy)] #by wybra klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie redniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyj numer klasy\n",
    "\n",
    "#Liczenie odlegoci\n",
    "sum_pow = 0 #init zmiennej do liczenia potgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = kt贸ra klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],5)) #tyle ile probek test. wierszy, 5 bo: klasa - 3 cechy - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest pr贸bek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potgi\n",
    "        \n",
    "        for kolumna in wybrane_cechy: #3 cechy\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odlegoci \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odlego\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z redniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 4] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano pr贸bk\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:4] = test_class[:, wybrane_cechy] #chce cechy\n",
    "#numpy tak naprawd nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Lobedness','Elongation','Eccentricity',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          50           0           0           5           0\n",
      "True: 11.0          0          88           0           0           0\n",
      "True: 25.0          0           0          32           1           0\n",
      "True: 30.0         10           0          28          17           0\n",
      "True: 31.0          0           0           0           0          44\n",
      "\n",
      "\n",
      "Dokadno:  84.0 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + brak normalizacji + 3 wybrane cechy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.933460</td>\n",
       "      <td>9.735100</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.849910</td>\n",
       "      <td>9.491200</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>1.120800</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.013721</td>\n",
       "      <td>0.882560</td>\n",
       "      <td>9.691500</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.028638</td>\n",
       "      <td>0.509610</td>\n",
       "      <td>1.087000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.905184</td>\n",
       "      <td>2.178478</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.044008</td>\n",
       "      <td>0.893757</td>\n",
       "      <td>1.769592</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>0.617641</td>\n",
       "      <td>1.298175</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.130635</td>\n",
       "      <td>1.038339</td>\n",
       "      <td>1.840179</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>0.411706</td>\n",
       "      <td>1.059946</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Lobedness  Elongation  Eccentricity  Klasyfikacja probki\n",
       "0     31.0   0.016599    0.933460      9.735100                 31.0\n",
       "1     31.0   0.012512    0.849910      9.491200                 31.0\n",
       "2     30.0   0.108090    0.936250      1.120800                 30.0\n",
       "3     31.0   0.013721    0.882560      9.691500                 31.0\n",
       "4     11.0   0.028638    0.509610      1.087000                 11.0\n",
       "..     ...        ...         ...           ...                  ...\n",
       "270    5.0   0.034861    0.905184      2.178478                  5.0\n",
       "271    5.0   0.044008    0.893757      1.769592                  5.0\n",
       "272   11.0   0.022467    0.617641      1.298175                 11.0\n",
       "273   25.0   0.130635    1.038339      1.840179                  5.0\n",
       "274   11.0   0.019995    0.411706      1.059946                 11.0\n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wybieranie klas\n",
    "train_df = pd.DataFrame(train, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_df.loc[train_df['Class'].isin(klasy)] #by wybra klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_df = pd.DataFrame(test, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_df.loc[test_df['Class'].isin(klasy)] #by wybra klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie redniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyj numer klasy\n",
    "\n",
    "#Liczenie odlegoci\n",
    "sum_pow = 0 #init zmiennej do liczenia potgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = kt贸ra klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],5)) #tyle ile probek test. wierszy, 5 bo: klasa - 3 cechy - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest pr贸bek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potgi\n",
    "        \n",
    "        for kolumna in wybrane_cechy: #3 cechy\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odlegoci \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odlego\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z redniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 4] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano pr贸bk\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:4] = test_class[:, wybrane_cechy] #chce cechy\n",
    "#numpy tak naprawd nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Lobedness','Elongation','Eccentricity',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          40           0          14           1           0\n",
      "True: 11.0          0          85           3           0           0\n",
      "True: 25.0          8           0          24           1           0\n",
      "True: 30.0          0           0          14          41           0\n",
      "True: 31.0          0           0           0           0          44\n",
      "\n",
      "\n",
      "Dokadno:  85.0909090909091 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + normalizacja + 5 wybranych cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Aspect Ratio</th>\n",
       "      <th>Isoperimetric Factor</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.744569</td>\n",
       "      <td>0.489485</td>\n",
       "      <td>0.878487</td>\n",
       "      <td>0.114205</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.071034</td>\n",
       "      <td>0.631097</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.888243</td>\n",
       "      <td>0.414745</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.550790</td>\n",
       "      <td>0.748358</td>\n",
       "      <td>0.025252</td>\n",
       "      <td>0.233860</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.077102</td>\n",
       "      <td>0.675440</td>\n",
       "      <td>0.487136</td>\n",
       "      <td>0.886564</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.151979</td>\n",
       "      <td>0.168926</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.650511</td>\n",
       "      <td>0.703015</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.183214</td>\n",
       "      <td>0.706166</td>\n",
       "      <td>0.082252</td>\n",
       "      <td>0.539703</td>\n",
       "      <td>0.249261</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.229129</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.060216</td>\n",
       "      <td>0.542140</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.315646</td>\n",
       "      <td>0.034811</td>\n",
       "      <td>0.643095</td>\n",
       "      <td>0.655226</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.663956</td>\n",
       "      <td>0.887008</td>\n",
       "      <td>0.064020</td>\n",
       "      <td>0.355481</td>\n",
       "      <td>0.240784</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.108593</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>0.657139</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Lobedness  Elongation  Eccentricity  Aspect Ratio  \\\n",
       "0     31.0   0.091549    0.744569      0.489485      0.878487   \n",
       "1     31.0   0.071034    0.631097      0.476341      0.888243   \n",
       "2     30.0   0.550790    0.748358      0.025252      0.233860   \n",
       "3     31.0   0.077102    0.675440      0.487136      0.886564   \n",
       "4     11.0   0.151979    0.168926      0.023431      0.650511   \n",
       "..     ...        ...         ...           ...           ...   \n",
       "270    5.0   0.183214    0.706166      0.082252      0.539703   \n",
       "271    5.0   0.229129    0.690647      0.060216      0.542140   \n",
       "272   11.0   0.121004    0.315646      0.034811      0.643095   \n",
       "273   25.0   0.663956    0.887008      0.064020      0.355481   \n",
       "274   11.0   0.108593    0.035960      0.021973      0.595283   \n",
       "\n",
       "     Isoperimetric Factor  Klasyfikacja probki  \n",
       "0                0.114205                  5.0  \n",
       "1                0.414745                 31.0  \n",
       "2                0.131375                 30.0  \n",
       "3                0.255600                 31.0  \n",
       "4                0.703015                 11.0  \n",
       "..                    ...                  ...  \n",
       "270              0.249261                  5.0  \n",
       "271              0.213592                  5.0  \n",
       "272              0.655226                 11.0  \n",
       "273              0.240784                 25.0  \n",
       "274              0.657139                 11.0  \n",
       "\n",
       "[275 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns_name = ['Class','Specimen Number','Eccentricity','Aspect Ratio','Elongation','Solidity',\n",
    "#                'Stochastic Convexity','Isoperimetric Factor','Maximal Indentation Depth','Lobedness',\n",
    "#                'Average Intensity','Average Contrast','Smoothness','Third moment','Uniformity','Entropy']\n",
    "\n",
    "#wybrane cechy z powyzej, narazie top3\n",
    "wybrane_cechy = [10,5,3,4,8] #Aspect Ratio, S\n",
    "\n",
    "#Wybieranie klas\n",
    "train_normalized_df = pd.DataFrame(train_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_normalized_df.loc[train_normalized_df['Class'].isin(klasy)] #by wybra klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_normalized_df = pd.DataFrame(test_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_normalized_df.loc[test_normalized_df['Class'].isin(klasy)] #by wybra klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie redniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyj numer klasy\n",
    "\n",
    "#Liczenie odlegoci\n",
    "sum_pow = 0 #init zmiennej do liczenia potgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = kt贸ra klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],7)) #tyle ile probek test. wierszy, 5 bo: klasa - 5 cech - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest pr贸bek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potgi\n",
    "        \n",
    "        for kolumna in wybrane_cechy: #3 cechy\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odlegoci \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odlego\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z redniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 6] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano pr贸bk\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:6] = test_class[:, wybrane_cechy] #chce cechy\n",
    "#numpy tak naprawd nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Lobedness','Elongation','Eccentricity','Aspect Ratio','Isoperimetric Factor',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          54           0           1           0           0\n",
      "True: 11.0          0          88           0           0           0\n",
      "True: 25.0          0           0          33           0           0\n",
      "True: 30.0          0           0          15          40           0\n",
      "True: 31.0          8           0           0           0          36\n",
      "\n",
      "\n",
      "Dokadno:  91.27272727272727 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + brak normalizacji + 3 wybrane cechy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Aspect Ratio</th>\n",
       "      <th>Isoperimetric Factor</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.933460</td>\n",
       "      <td>9.735100</td>\n",
       "      <td>0.904440</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.849910</td>\n",
       "      <td>9.491200</td>\n",
       "      <td>0.913970</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>1.120800</td>\n",
       "      <td>0.274730</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.013721</td>\n",
       "      <td>0.882560</td>\n",
       "      <td>9.691500</td>\n",
       "      <td>0.912330</td>\n",
       "      <td>0.049695</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.028638</td>\n",
       "      <td>0.509610</td>\n",
       "      <td>1.087000</td>\n",
       "      <td>0.681740</td>\n",
       "      <td>0.140820</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.905184</td>\n",
       "      <td>2.178478</td>\n",
       "      <td>0.573496</td>\n",
       "      <td>0.048404</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.044008</td>\n",
       "      <td>0.893757</td>\n",
       "      <td>1.769592</td>\n",
       "      <td>0.575877</td>\n",
       "      <td>0.041139</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>0.617641</td>\n",
       "      <td>1.298175</td>\n",
       "      <td>0.674496</td>\n",
       "      <td>0.131087</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.130635</td>\n",
       "      <td>1.038339</td>\n",
       "      <td>1.840179</td>\n",
       "      <td>0.393537</td>\n",
       "      <td>0.046677</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>0.411706</td>\n",
       "      <td>1.059946</td>\n",
       "      <td>0.627790</td>\n",
       "      <td>0.131477</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Lobedness  Elongation  Eccentricity  Aspect Ratio  \\\n",
       "0     31.0   0.016599    0.933460      9.735100      0.904440   \n",
       "1     31.0   0.012512    0.849910      9.491200      0.913970   \n",
       "2     30.0   0.108090    0.936250      1.120800      0.274730   \n",
       "3     31.0   0.013721    0.882560      9.691500      0.912330   \n",
       "4     11.0   0.028638    0.509610      1.087000      0.681740   \n",
       "..     ...        ...         ...           ...           ...   \n",
       "270    5.0   0.034861    0.905184      2.178478      0.573496   \n",
       "271    5.0   0.044008    0.893757      1.769592      0.575877   \n",
       "272   11.0   0.022467    0.617641      1.298175      0.674496   \n",
       "273   25.0   0.130635    1.038339      1.840179      0.393537   \n",
       "274   11.0   0.019995    0.411706      1.059946      0.627790   \n",
       "\n",
       "     Isoperimetric Factor  Klasyfikacja probki  \n",
       "0                0.020897                 31.0  \n",
       "1                0.082108                 31.0  \n",
       "2                0.024394                 30.0  \n",
       "3                0.049695                 31.0  \n",
       "4                0.140820                 11.0  \n",
       "..                    ...                  ...  \n",
       "270              0.048404                  5.0  \n",
       "271              0.041139                  5.0  \n",
       "272              0.131087                 11.0  \n",
       "273              0.046677                  5.0  \n",
       "274              0.131477                 11.0  \n",
       "\n",
       "[275 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wybieranie klas\n",
    "train_df = pd.DataFrame(train, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_df.loc[train_df['Class'].isin(klasy)] #by wybra klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_df = pd.DataFrame(test, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_df.loc[test_df['Class'].isin(klasy)] #by wybra klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie redniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyj numer klasy\n",
    "\n",
    "#Liczenie odlegoci\n",
    "sum_pow = 0 #init zmiennej do liczenia potgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = kt贸ra klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],7)) #tyle ile probek test. wierszy, 5 bo: klasa - 5 cech - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest pr贸bek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potgi\n",
    "        \n",
    "        for kolumna in wybrane_cechy: #3 cechy\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odlegoci \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odlego\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z redniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 6] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano pr贸bk\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:6] = test_class[:, wybrane_cechy] #chce cechy\n",
    "#numpy tak naprawd nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Lobedness','Elongation','Eccentricity','Aspect Ratio','Isoperimetric Factor',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          42           1          12           0           0\n",
      "True: 11.0          0          86           2           0           0\n",
      "True: 25.0          7           0          25           1           0\n",
      "True: 30.0          0           0          10          45           0\n",
      "True: 31.0          0           0           0           0          44\n",
      "\n",
      "\n",
      "Dokadno:  88.0 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wnioski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://matplotlib.org/stable/gallery/lines_bars_and_markers/barchart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['NM 10 cech','NM 3 cechy Fisher','NM 5 cech Fisher']\n",
    "znormalizowane = [82.18,84,91.27]\n",
    "nie_znormalizowane = [74.55,85.09,88]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, znormalizowane, width, label='Znormalizowane dane')\n",
    "rects2 = ax.bar(x + width/2, nie_znormalizowane, width, label='Nieznormalizowane dane')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Dokadno %')\n",
    "ax.set_title('Klasyfikacja wyniki')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NM 10 cech:\n",
    "- 82.18% po normalizacji\n",
    "- 74.55% przed normalizacj\n",
    "\n",
    "NM 3 cechy Fisher:\n",
    "- 84% po normalizacji\n",
    "- 85.09% przed normalizacj\n",
    "\n",
    "NM 5 cech Fisher:\n",
    "- 91.27% po normalizacji\n",
    "- 88% przed normalizacj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak mo偶na zauwa偶y, nie zawsze wybrane losowo cechy bd lepsze od dobrze wybranych (za pomoc Fishera). Wykorzystanie zaledwie 3 cech, lecz dobrych (zamiast 10) pozwolio na zwikszenie skutecznoci algorytmu NM o 2% po oraz ok. 10% przed normalizacj.\n",
    "\n",
    "Im wicej dobrze dobranych cech, tj. 5 cech Fisher, tym osigamy najwy偶szy w tym wiczeniu procent klasyfikacji, tj. 91.27% po oraz 88% przed normalizacj danych.\n",
    "\n",
    "Dobrze dobrane cechy pozwoliy nieznormalizowanym danym na du偶o bardziej zbli偶one wyniki do znormalizowanych."
   ]
  }
 ],
 "metadata": {
  "author": {
   "emails": [
    "rsusik@kis.p.lodz.pl"
   ],
   "name": "Robert Susik"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
