{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statystyczne metody przetwarzania danych \n",
    "\n",
    "## Laboratorium 4 - algorytm normalizacja, selekcja cech.\n",
    "\n",
    "\n",
    "### Opis\n",
    "Celem laboratorium jest przeprowadzenie normalizacji i selekcji cech.\n",
    "\n",
    "### Termin\n",
    "Zadanie należy wykonać tego samego dnia. \n",
    "\n",
    "### System oceniania\n",
    "\n",
    "| Liczba punktów (procentowo) | Ocena |\n",
    "| :----                    | ---: |\n",
    "| [0-50)   | 2   |\n",
    "| [50-60)  | 3   |\n",
    "| [60-70)  | 3.5 |\n",
    "| [70-80)  | 4   |\n",
    "| [80-90)  | 4.5 |\n",
    "| [90-100] | 5   |\n",
    "\n",
    "<u>Punkty ujemne</u>\n",
    "\n",
    "* `ocena - 0.5` jeżeli zadanie wysłano po laboratorium, ale < 7 dni; \n",
    "* `ocena - 1` jeżeli zadanie wysłano w terminie pomiędzy 7 a 14 dni;\n",
    "* `ocena - 1.5` jeżeli zadanie wysłano po upływie 14 dni, ale przed ostatnim laboratorium;\n",
    "* `ocena = 2` jeżeli zadanie wysłano po ostatnim laboratorium.\n",
    "\n",
    "<u>Uwaga:</u>\n",
    "\n",
    "Niedopuszczalne jest dzielenie się notatnikiem (plik `.ipynb`) z innymi studentami ani udostępnianie go w Internecie. Każdy student powinien pobrać notatnik samodzielnie z platformy WIKAMP.\n",
    "Wysyłając zadanie potwierdasz, że wykonałeś je samodzielnie i jest to Twoja indywidualna praca a materiał przedstawiony w tej pracy jest dla Ciebie zrozumiały. Prace bardzo podobne albo grupowe będą uznawane za plagiat.\n",
    "\n",
    "\n",
    "### Zbiór danych\n",
    "\n",
    "Zbiór danych znajduje się w katalogu `dataset/*`. Jest to zmodyfikowany zbiór danych znajdujący się pod adresem: <https://archive.ics.uci.edu/ml/datasets/leaf>.\n",
    "\n",
    "### Przesyłanie zadań\n",
    "\n",
    "Wszystkie pliki należy spakować archiwizatorem **zip** i przesłać za pośrednictwem platformy WIKAMP. Poniżej oczekiwana zawartość archiwum:\n",
    "\n",
    "```\n",
    "+-- 📂 [IMIE.NAZWISKO].zip\n",
    "    +-- 📜 Lab04.ipynb\n",
    "    +-- 📂 dataset\n",
    "        +-- 📜 dataset.npz\n",
    "        +-- 📜 ReadMe.pdf\n",
    "```\n",
    "\n",
    "**Pamiętaj, wyniki powinny być czytelnie opisane oraz zaprezentowane graficznie (jeżeli jest taka możliwość). Warstwa prezentacji danych to jeden z głównych elementów wpływających na ocenę.**\n",
    "\n",
    "Przykład (na podstawie tablicy pomyłek):\n",
    "\n",
    "**Źle** (nie wiadomo co jest poniżej zaprezentowane, kolumny ani wiersze nie są podpisane, nie wiadomo które z nich prezentują predykcje, a które właściwe etykiety):\n",
    "```\n",
    "array([[2, 0, 0],\n",
    "       [0, 0, 1],\n",
    "       [1, 0, 2]])\n",
    "```\n",
    "\n",
    "### Zadanie\n",
    "\n",
    "Należy wykonać następujące czynności w celu realizacji niniejszego zadania:\n",
    "\n",
    "### Normalizacja\n",
    "* Wczytaj dane.\n",
    "* Znormalizuj dane.\n",
    "* Przeprowadź eksperyment z zastosowaniem algorytmu kNN lub NM dla danych znormalizowanych oraz bez normalizacji.\n",
    "    * W eksperymencie wybierz minimum 5 klas oraz 10 cech.\n",
    "* Przedstaw porównanie wyników klasyfikacji na danych znormalizowanych i bez normalizacji.\n",
    "* Napisz wnioski.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytywanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piotr Klimczak, 1SIiUM2, 239533 / 215275\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('./dataset/dataset.npz', 'rb') as f:\n",
    "    data = np.load(f)\n",
    "    train, test = data['train'], data['test']\n",
    "    \n",
    "columns_name = ['Class','Specimen Number','Eccentricity','Aspect Ratio','Elongation','Solidity',\n",
    "                'Stochastic Convexity','Isoperimetric Factor','Maximal Indentation Depth','Lobedness',\n",
    "                'Average Intensity','Average Contrast','Smoothness','Third moment','Uniformity','Entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizowaie - (x-xmin)/(xmax-xmin)\n",
    "# axis=0 |, axis=1 _\n",
    "# [wiersze, kolumny]\n",
    "\n",
    "train_min = np.min(train, axis=0) #Szukanie minimum każdej kolumny\n",
    "train_max = np.max(train, axis=0) #Szukanie maximum każdej kolumny\n",
    "train_normalized = (train - train_min) / (train_max - train_min) #Normalizowanie danych treningowych\n",
    "train_normalized[:,0] = train[:,0] #Podmienie znormalizowane numery klas na te, co byly\n",
    "\n",
    "#Znormalizuje też dane testowe ALE WYKORZYSTUJĄC MIN I MAX Z DANYCH TRENINGOWYCH (bo tak trzeba)\n",
    "test_normalized = (test - train_min) / (train_max - train_min) #Normalizowanie danych testowych\n",
    "test_normalized[:,0] = test[:,0] #Podmienie znormalizowane numery klas na te, co byly; [wszystkie wiersze, kolumna 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + normalizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Stochastic Convexity</th>\n",
       "      <th>Isoperimetric Factor</th>\n",
       "      <th>Maximal Indentation Depth</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Average Intensity</th>\n",
       "      <th>Average Contrast</th>\n",
       "      <th>Smoothness</th>\n",
       "      <th>Third moment</th>\n",
       "      <th>Uniformity</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.822817</td>\n",
       "      <td>0.204748</td>\n",
       "      <td>0.114205</td>\n",
       "      <td>0.021510</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.216215</td>\n",
       "      <td>0.091114</td>\n",
       "      <td>0.094380</td>\n",
       "      <td>0.030993</td>\n",
       "      <td>0.163356</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.810909</td>\n",
       "      <td>0.180505</td>\n",
       "      <td>0.414745</td>\n",
       "      <td>0.177331</td>\n",
       "      <td>0.071034</td>\n",
       "      <td>0.163708</td>\n",
       "      <td>0.065579</td>\n",
       "      <td>0.063462</td>\n",
       "      <td>0.033540</td>\n",
       "      <td>0.137765</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.834726</td>\n",
       "      <td>0.536158</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.025423</td>\n",
       "      <td>0.550790</td>\n",
       "      <td>0.553685</td>\n",
       "      <td>0.378656</td>\n",
       "      <td>0.246772</td>\n",
       "      <td>0.421772</td>\n",
       "      <td>0.886722</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.767267</td>\n",
       "      <td>0.182020</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.071749</td>\n",
       "      <td>0.077102</td>\n",
       "      <td>0.188813</td>\n",
       "      <td>0.077119</td>\n",
       "      <td>0.079629</td>\n",
       "      <td>0.030980</td>\n",
       "      <td>0.134598</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.457750</td>\n",
       "      <td>0.157810</td>\n",
       "      <td>0.703015</td>\n",
       "      <td>0.500822</td>\n",
       "      <td>0.151979</td>\n",
       "      <td>0.266302</td>\n",
       "      <td>0.120445</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>0.085557</td>\n",
       "      <td>0.312219</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.741376</td>\n",
       "      <td>0.340158</td>\n",
       "      <td>0.249261</td>\n",
       "      <td>0.059936</td>\n",
       "      <td>0.183214</td>\n",
       "      <td>0.428716</td>\n",
       "      <td>0.162708</td>\n",
       "      <td>0.188195</td>\n",
       "      <td>0.085387</td>\n",
       "      <td>0.329034</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.770239</td>\n",
       "      <td>0.386188</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>0.050839</td>\n",
       "      <td>0.229129</td>\n",
       "      <td>0.385119</td>\n",
       "      <td>0.208638</td>\n",
       "      <td>0.188408</td>\n",
       "      <td>0.084388</td>\n",
       "      <td>0.413497</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.533699</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.655226</td>\n",
       "      <td>0.438121</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.264629</td>\n",
       "      <td>0.105414</td>\n",
       "      <td>0.111274</td>\n",
       "      <td>0.030885</td>\n",
       "      <td>0.246515</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.952172</td>\n",
       "      <td>0.777933</td>\n",
       "      <td>0.240784</td>\n",
       "      <td>0.057727</td>\n",
       "      <td>0.663956</td>\n",
       "      <td>0.822874</td>\n",
       "      <td>0.780706</td>\n",
       "      <td>0.990042</td>\n",
       "      <td>0.216042</td>\n",
       "      <td>0.608515</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.399660</td>\n",
       "      <td>0.155492</td>\n",
       "      <td>0.657139</td>\n",
       "      <td>0.410059</td>\n",
       "      <td>0.108593</td>\n",
       "      <td>0.189355</td>\n",
       "      <td>0.077970</td>\n",
       "      <td>0.085160</td>\n",
       "      <td>0.084397</td>\n",
       "      <td>0.295165</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Stochastic Convexity  Isoperimetric Factor  \\\n",
       "0     31.0              0.822817              0.204748   \n",
       "1     31.0              0.810909              0.180505   \n",
       "2     30.0              0.834726              0.536158   \n",
       "3     31.0              0.767267              0.182020   \n",
       "4     11.0              0.457750              0.157810   \n",
       "..     ...                   ...                   ...   \n",
       "270    5.0              0.741376              0.340158   \n",
       "271    5.0              0.770239              0.386188   \n",
       "272   11.0              0.533699              0.220300   \n",
       "273   25.0              0.952172              0.777933   \n",
       "274   11.0              0.399660              0.155492   \n",
       "\n",
       "     Maximal Indentation Depth  Lobedness  Average Intensity  \\\n",
       "0                     0.114205   0.021510           0.091549   \n",
       "1                     0.414745   0.177331           0.071034   \n",
       "2                     0.131375   0.025423           0.550790   \n",
       "3                     0.255600   0.071749           0.077102   \n",
       "4                     0.703015   0.500822           0.151979   \n",
       "..                         ...        ...                ...   \n",
       "270                   0.249261   0.059936           0.183214   \n",
       "271                   0.213592   0.050839           0.229129   \n",
       "272                   0.655226   0.438121           0.121004   \n",
       "273                   0.240784   0.057727           0.663956   \n",
       "274                   0.657139   0.410059           0.108593   \n",
       "\n",
       "     Average Contrast  Smoothness  Third moment  Uniformity   Entropy  \\\n",
       "0            0.216215    0.091114      0.094380    0.030993  0.163356   \n",
       "1            0.163708    0.065579      0.063462    0.033540  0.137765   \n",
       "2            0.553685    0.378656      0.246772    0.421772  0.886722   \n",
       "3            0.188813    0.077119      0.079629    0.030980  0.134598   \n",
       "4            0.266302    0.120445      0.102468    0.085557  0.312219   \n",
       "..                ...         ...           ...         ...       ...   \n",
       "270          0.428716    0.162708      0.188195    0.085387  0.329034   \n",
       "271          0.385119    0.208638      0.188408    0.084388  0.413497   \n",
       "272          0.264629    0.105414      0.111274    0.030885  0.246515   \n",
       "273          0.822874    0.780706      0.990042    0.216042  0.608515   \n",
       "274          0.189355    0.077970      0.085160    0.084397  0.295165   \n",
       "\n",
       "     Klasyfikacja probki  \n",
       "0                    5.0  \n",
       "1                   31.0  \n",
       "2                   30.0  \n",
       "3                    5.0  \n",
       "4                   11.0  \n",
       "..                   ...  \n",
       "270                  5.0  \n",
       "271                  5.0  \n",
       "272                 11.0  \n",
       "273                 25.0  \n",
       "274                 11.0  \n",
       "\n",
       "[275 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 wybranych klas:\n",
    "klasy = [31, 5, 11, 25, 30] \n",
    "#klasy = [29, 5, 8, 4, 31]\n",
    "\n",
    "#cech jest 10\n",
    "#print(np.arange(6,16,1)) = [ 6  7  8  9 10 11 12 13 14 15]\n",
    "wybrane_cechy = np.arange(5,15,1)\n",
    "\n",
    "#Wybieranie klas\n",
    "train_normalized_df = pd.DataFrame(train_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_normalized_df.loc[train_normalized_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_normalized_df = pd.DataFrame(test_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_normalized_df.loc[test_normalized_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie średniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyjść numer klasy\n",
    "\n",
    "#Liczenie odległości\n",
    "sum_pow = 0 #init zmiennej do liczenia potęgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = która klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],12)) #tyle ile probek test. wierszy, 12 bo: klasa - 10 cechy - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest próbek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potęgi\n",
    "        \n",
    "        for kolumna in wybrane_cechy: #10 cech \n",
    "            #(sprawdzone na innych, typu 6:16 i one byly duzo gorsze)\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odległości \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odległość\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z średniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 11] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano próbkę\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:11] = test_class[:, 6:16] #chce cechy\n",
    "#numpy tak naprawdę nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Stochastic Convexity','Isoperimetric Factor','Maximal Indentation Depth','Lobedness',\n",
    "                   'Average Intensity','Average Contrast','Smoothness','Third moment','Uniformity','Entropy',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matrix():\n",
    "    y_true = wynik_klasyfikacji['Class']\n",
    "    y_pred = wynik_klasyfikacji['Klasyfikacja probki']\n",
    "    \n",
    "    unique = np.unique([y_pred.to_numpy()]) #w ktorymkolwiek, bo przeciez sa te same klasy tu i tu\n",
    "    \n",
    "    conmat = pd.DataFrame(\n",
    "        confusion_matrix(y_true, y_pred, labels=unique),\n",
    "        index = ['True: {:}'.format(x) for x in unique],\n",
    "        columns = ['Pred: {:}'.format(x) for x in unique]\n",
    "    )\n",
    "    \n",
    "    print(conmat)\n",
    "    \n",
    "def Dokladnosc():\n",
    "    zgodne = 0 #init & czysc zmienna\n",
    "\n",
    "    for i in range(len(wynik_klasyfikacji)):\n",
    "        if ((wynik_klasyfikacji['Class'])[i]  == (wynik_klasyfikacji['Klasyfikacja probki'])[i]): #czy pokrywa się klasyfikacja\n",
    "            zgodne += 1 #jeżeli tak, +1\n",
    "        \n",
    "    acc = zgodne / len(wynik_klasyfikacji)\n",
    "    print(\"\\n\")\n",
    "    print(\"Dokładność: \", acc*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          55           0           0           0           0\n",
      "True: 11.0          0          84           0           0           4\n",
      "True: 25.0          0           0          22          11           0\n",
      "True: 30.0          2           0           0          53           0\n",
      "True: 31.0         32           0           0           0          12\n",
      "\n",
      "\n",
      "Dokładność:  82.18181818181817 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + brak normalizacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Stochastic Convexity</th>\n",
       "      <th>Isoperimetric Factor</th>\n",
       "      <th>Maximal Indentation Depth</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Average Intensity</th>\n",
       "      <th>Average Contrast</th>\n",
       "      <th>Smoothness</th>\n",
       "      <th>Third moment</th>\n",
       "      <th>Uniformity</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.984210</td>\n",
       "      <td>0.196380</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.075247</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.489920</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.973680</td>\n",
       "      <td>0.174290</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>1.227000</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.060688</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.419280</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.994740</td>\n",
       "      <td>0.498360</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>0.168820</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>2.486600</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.935090</td>\n",
       "      <td>0.175670</td>\n",
       "      <td>0.049695</td>\n",
       "      <td>0.449460</td>\n",
       "      <td>0.013721</td>\n",
       "      <td>0.067649</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.410540</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.661400</td>\n",
       "      <td>0.153610</td>\n",
       "      <td>0.140820</td>\n",
       "      <td>3.609300</td>\n",
       "      <td>0.028638</td>\n",
       "      <td>0.089135</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.900820</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.912196</td>\n",
       "      <td>0.319765</td>\n",
       "      <td>0.048404</td>\n",
       "      <td>0.362463</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.134169</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.947233</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.937718</td>\n",
       "      <td>0.361707</td>\n",
       "      <td>0.041139</td>\n",
       "      <td>0.295472</td>\n",
       "      <td>0.044008</td>\n",
       "      <td>0.122080</td>\n",
       "      <td>0.014654</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>1.180374</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.728558</td>\n",
       "      <td>0.210551</td>\n",
       "      <td>0.131087</td>\n",
       "      <td>3.147546</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>0.088671</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.719461</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.098591</td>\n",
       "      <td>0.718665</td>\n",
       "      <td>0.046677</td>\n",
       "      <td>0.346197</td>\n",
       "      <td>0.130635</td>\n",
       "      <td>0.243460</td>\n",
       "      <td>0.058580</td>\n",
       "      <td>0.025878</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>1.718675</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.610035</td>\n",
       "      <td>0.151498</td>\n",
       "      <td>0.131477</td>\n",
       "      <td>2.940893</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>0.067799</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.853746</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Stochastic Convexity  Isoperimetric Factor  \\\n",
       "0     31.0              0.984210              0.196380   \n",
       "1     31.0              0.973680              0.174290   \n",
       "2     30.0              0.994740              0.498360   \n",
       "3     31.0              0.935090              0.175670   \n",
       "4     11.0              0.661400              0.153610   \n",
       "..     ...                   ...                   ...   \n",
       "270    5.0              0.912196              0.319765   \n",
       "271    5.0              0.937718              0.361707   \n",
       "272   11.0              0.728558              0.210551   \n",
       "273   25.0              1.098591              0.718665   \n",
       "274   11.0              0.610035              0.151498   \n",
       "\n",
       "     Maximal Indentation Depth  Lobedness  Average Intensity  \\\n",
       "0                     0.020897   0.079479           0.016599   \n",
       "1                     0.082108   1.227000           0.012512   \n",
       "2                     0.024394   0.108300           0.108090   \n",
       "3                     0.049695   0.449460           0.013721   \n",
       "4                     0.140820   3.609300           0.028638   \n",
       "..                         ...        ...                ...   \n",
       "270                   0.048404   0.362463           0.034861   \n",
       "271                   0.041139   0.295472           0.044008   \n",
       "272                   0.131087   3.147546           0.022467   \n",
       "273                   0.046677   0.346197           0.130635   \n",
       "274                   0.131477   2.940893           0.019995   \n",
       "\n",
       "     Average Contrast  Smoothness  Third moment  Uniformity   Entropy  \\\n",
       "0            0.075247    0.005630      0.001901    0.000044  0.489920   \n",
       "1            0.060688    0.003670      0.001074    0.000052  0.419280   \n",
       "2            0.168820    0.027709      0.005981    0.001234  2.486600   \n",
       "3            0.067649    0.004556      0.001506    0.000044  0.410540   \n",
       "4            0.089135    0.007882      0.002118    0.000210  0.900820   \n",
       "..                ...         ...           ...         ...       ...   \n",
       "270          0.134169    0.011128      0.004413    0.000210  0.947233   \n",
       "271          0.122080    0.014654      0.004418    0.000207  1.180374   \n",
       "272          0.088671    0.006728      0.002353    0.000044  0.719461   \n",
       "273          0.243460    0.058580      0.025878    0.000607  1.718675   \n",
       "274          0.067799    0.004621      0.001654    0.000207  0.853746   \n",
       "\n",
       "     Klasyfikacja probki  \n",
       "0                   30.0  \n",
       "1                    5.0  \n",
       "2                   30.0  \n",
       "3                    5.0  \n",
       "4                   31.0  \n",
       "..                   ...  \n",
       "270                  5.0  \n",
       "271                  5.0  \n",
       "272                 11.0  \n",
       "273                 25.0  \n",
       "274                 11.0  \n",
       "\n",
       "[275 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wybieranie klas\n",
    "train_df = pd.DataFrame(train, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_df.loc[train_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_df = pd.DataFrame(test, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_df.loc[test_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie średniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyjść numer klasy\n",
    "\n",
    "#Liczenie odległości\n",
    "sum_pow = 0 #init zmiennej do liczenia potęgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = która klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],12)) #tyle ile probek test. wierszy, 12 bo: klasa - 10 cechy - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest próbek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potęgi\n",
    "\n",
    "        for kolumna in wybrane_cechy: #10 cech (ostatnie 10 kolumn)\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odległości \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odległość\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z średniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 11] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano próbkę\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:11] = test_class[:, 6:16] #chce cechy\n",
    "#numpy tak naprawdę nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Stochastic Convexity','Isoperimetric Factor','Maximal Indentation Depth','Lobedness',\n",
    "                   'Average Intensity','Average Contrast','Smoothness','Third moment','Uniformity','Entropy',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          51           0           0           4           0\n",
      "True: 11.0          0          66           0           0          22\n",
      "True: 25.0          0           0          33           0           0\n",
      "True: 30.0          0           0           0          55           0\n",
      "True: 31.0         33           0           0          11           0\n",
      "\n",
      "\n",
      "Dokładność:  74.54545454545455 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacja - wnioski\n",
    "Przeprowadzono poprawną normalizację danych - z zbioru treningowego wyznaczono min i max wartość, następnie policzono (x-xmin)/(xmax-xmin).\n",
    "\n",
    "To samo zrobiono dla zbioru testowego, wykorzystując min i max z zbioru treningowego.\n",
    "\n",
    "Wybrałem pierwsze 10 cech z podanego datasetu.\n",
    "\n",
    "[ReadMe.pdf]: shape (attributes 3 to 9) and texture (attributes 10 to 16) - uznałem, że shape jest ważniejsze\n",
    "\n",
    "Wyniki:\n",
    "- dla klas [31, 5, 11, 25, 30] osiągnięto **82.18% po** oraz **74.55% przed** normalizacją\n",
    "\n",
    "Jak widać, normalizacja podniosła poziom dopasowania próbek testowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selekcja cech\n",
    "* Przeprowadź selekcję cech za pomocą metod poznanych na wykładzie (np. z zastosowaniem współczynnika Fishera)\n",
    "    * Wybierz 2-5 cech (ze zbioru 10 cech wybranych w poprzednim eksperymencie) i opisz dlaczego je wybrałeś.\n",
    "* Przeprowadź klasyfikację na wybranych cechach.\n",
    "* Porównaj wyniki klasyfikacji:\n",
    "    * dla 10 cech bez normalizacji,\n",
    "    * dla 10 cech z normalizacją,\n",
    "    * dla 2-5 cech bez normalizacji,\n",
    "    * dla 2-5 cech z normalizacją.\n",
    "* Opisz wyniki i napisz wnioski.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique, count\n",
      "[(10.0, 7), (5.0, 5), (3.0, 4), (4.0, 3), (8.0, 3), (6.0, 3), (2.0, 2)]\n"
     ]
    }
   ],
   "source": [
    "#Wybieranie klas i obliczanie macierzy kowariancji\n",
    "train_df = pd.DataFrame(train_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_df.loc[train_df['Class'].isin(klasy)] #by wybrać klasy, do średniej\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "train_cov = list() #lista do której będziemy dodawać wyniki\n",
    "\n",
    "for x in range(len(klasy)): #tyle, ile jest klas\n",
    "    train_class_pojedyncza = train_df.loc[train_df['Class'].isin([klasy[x]])] #by wybrać klasę konkretną\n",
    "    train_class_pojedyncza_numpy = train_class_pojedyncza.to_numpy() #z powrotem do numpy arraya\n",
    "    train_cov.append(np.cov(train_class_pojedyncza_numpy[:, wybrane_cechy].T)) #<- WYBIERANIE CECH\n",
    "    #m. kowariancji liczona pośród 10 cech (od 6 do 15 kolumny), transponowane by pasował rozmiar\n",
    "    \n",
    "#Liczenie średniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #[5, 16], [wiersze ile klas, kolumny 16]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    \n",
    "#Liczenie Fishera\n",
    "fisher = np.empty((10,2)) #10 wierszy, 2 kolumny - 10 cech, 1 wartość policzona, 2 jaka cecha byla\n",
    "fisher_all = list()\n",
    "\n",
    "#[klasa,klasanext] = [01,02,03,04 | 12,13,14 | 23,24 | 34] = 10 razy, 10 roznych polaczen miedzy klasami\n",
    "for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "\n",
    "    for klasanext in range(klasa + 1, len(klasy)): #tyle, ile jest klas, ale +1;\n",
    "    #nawet jak klasa = 4, to ten for sie po prostu nie wykona\n",
    "           \n",
    "        for cecha in range(10): #tyle, ile jest cech (10)\n",
    "            fisher[cecha,0] = abs(mean[klasa, cecha+1] - mean[klasanext, cecha+1]) / (np.sqrt(train_cov[klasa][cecha,cecha]) + np.sqrt(train_cov[klasanext][cecha,cecha]))\n",
    "            #mean[wiersze-5klas, 16kolumn]; \n",
    "            #abs(mean[klasa0,cecha+1]) - mean[klasa1,cecha+1], potem weź ślad dlatego [cecha,cecha] - idzie po glownej przekatnej\n",
    "            #cecha+1 żeby ominąć kolumnę 0 z klasami\n",
    "            fisher[cecha,1] = cecha+1 #jaka cecha?\n",
    "                \n",
    "        fisher_all.append(fisher[fisher[:,0].argsort()[::-1]]) #posortowanego fishera przypisz do ogolnej listy\n",
    "        #fisher[ fisher[wszystkie-wiersze,kolumna0-policzonecechy].argsort() ]\n",
    "        #[::-1] - start:stop:step - wszystkie:wszystkie:od konca, bo -1 to ostatni element w arrayu ogolnie, jak by wywolywac\n",
    "            \n",
    "result = [l[:3] for l in fisher_all] #weź po kolei każdą tabelę z fisher_all i pokaż 3 pierwsze\n",
    "\n",
    "unique, count = np.unique(result, return_counts=True) #pokaz unikatowe wartosci oraz ile razy sie pojawily\n",
    "\n",
    "print(\"unique, count\")\n",
    "print(sorted(set(zip(unique,count)), key = lambda x: x[1], reverse=True)[:7])\n",
    "#lacze zipem unique i count, setem ustawiam (by dalo sie to 'pokazac'), sortuje po kolumnie 1, odwracam, pobieram pierwsze :7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + normalizacja + 3 wybrane cechy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.744569</td>\n",
       "      <td>0.489485</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.071034</td>\n",
       "      <td>0.631097</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.550790</td>\n",
       "      <td>0.748358</td>\n",
       "      <td>0.025252</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.077102</td>\n",
       "      <td>0.675440</td>\n",
       "      <td>0.487136</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.151979</td>\n",
       "      <td>0.168926</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.183214</td>\n",
       "      <td>0.706166</td>\n",
       "      <td>0.082252</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.229129</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.060216</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.315646</td>\n",
       "      <td>0.034811</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.663956</td>\n",
       "      <td>0.887008</td>\n",
       "      <td>0.064020</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.108593</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Lobedness  Elongation  Eccentricity  Klasyfikacja probki\n",
       "0     31.0   0.091549    0.744569      0.489485                 31.0\n",
       "1     31.0   0.071034    0.631097      0.476341                 31.0\n",
       "2     30.0   0.550790    0.748358      0.025252                 25.0\n",
       "3     31.0   0.077102    0.675440      0.487136                 31.0\n",
       "4     11.0   0.151979    0.168926      0.023431                 11.0\n",
       "..     ...        ...         ...           ...                  ...\n",
       "270    5.0   0.183214    0.706166      0.082252                  5.0\n",
       "271    5.0   0.229129    0.690647      0.060216                  5.0\n",
       "272   11.0   0.121004    0.315646      0.034811                 11.0\n",
       "273   25.0   0.663956    0.887008      0.064020                 25.0\n",
       "274   11.0   0.108593    0.035960      0.021973                 11.0\n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns_name = ['Class','Specimen Number','Eccentricity','Aspect Ratio','Elongation','Solidity',\n",
    "#                'Stochastic Convexity','Isoperimetric Factor','Maximal Indentation Depth','Lobedness',\n",
    "#                'Average Intensity','Average Contrast','Smoothness','Third moment','Uniformity','Entropy']\n",
    "\n",
    "#wybrane cechy z powyzej, narazie top3\n",
    "wybrane_cechy = [10,5,3] \n",
    "\n",
    "#Wybieranie klas\n",
    "train_normalized_df = pd.DataFrame(train_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_normalized_df.loc[train_normalized_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_normalized_df = pd.DataFrame(test_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_normalized_df.loc[test_normalized_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie średniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyjść numer klasy\n",
    "\n",
    "#Liczenie odległości\n",
    "sum_pow = 0 #init zmiennej do liczenia potęgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = która klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],5)) #tyle ile probek test. wierszy, 5 bo: klasa - 3 cechy - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest próbek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potęgi\n",
    "        \n",
    "        for kolumna in wybrane_cechy: #3 cechy\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odległości \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odległość\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z średniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 4] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano próbkę\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:4] = test_class[:, wybrane_cechy] #chce cechy\n",
    "#numpy tak naprawdę nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Lobedness','Elongation','Eccentricity',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          50           0           0           5           0\n",
      "True: 11.0          0          88           0           0           0\n",
      "True: 25.0          0           0          32           1           0\n",
      "True: 30.0         10           0          28          17           0\n",
      "True: 31.0          0           0           0           0          44\n",
      "\n",
      "\n",
      "Dokładność:  84.0 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + brak normalizacji + 3 wybrane cechy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.933460</td>\n",
       "      <td>9.735100</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.849910</td>\n",
       "      <td>9.491200</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>1.120800</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.013721</td>\n",
       "      <td>0.882560</td>\n",
       "      <td>9.691500</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.028638</td>\n",
       "      <td>0.509610</td>\n",
       "      <td>1.087000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.905184</td>\n",
       "      <td>2.178478</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.044008</td>\n",
       "      <td>0.893757</td>\n",
       "      <td>1.769592</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>0.617641</td>\n",
       "      <td>1.298175</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.130635</td>\n",
       "      <td>1.038339</td>\n",
       "      <td>1.840179</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>0.411706</td>\n",
       "      <td>1.059946</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Lobedness  Elongation  Eccentricity  Klasyfikacja probki\n",
       "0     31.0   0.016599    0.933460      9.735100                 31.0\n",
       "1     31.0   0.012512    0.849910      9.491200                 31.0\n",
       "2     30.0   0.108090    0.936250      1.120800                 30.0\n",
       "3     31.0   0.013721    0.882560      9.691500                 31.0\n",
       "4     11.0   0.028638    0.509610      1.087000                 11.0\n",
       "..     ...        ...         ...           ...                  ...\n",
       "270    5.0   0.034861    0.905184      2.178478                  5.0\n",
       "271    5.0   0.044008    0.893757      1.769592                  5.0\n",
       "272   11.0   0.022467    0.617641      1.298175                 11.0\n",
       "273   25.0   0.130635    1.038339      1.840179                  5.0\n",
       "274   11.0   0.019995    0.411706      1.059946                 11.0\n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wybieranie klas\n",
    "train_df = pd.DataFrame(train, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_df.loc[train_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_df = pd.DataFrame(test, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_df.loc[test_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie średniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyjść numer klasy\n",
    "\n",
    "#Liczenie odległości\n",
    "sum_pow = 0 #init zmiennej do liczenia potęgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = która klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],5)) #tyle ile probek test. wierszy, 5 bo: klasa - 3 cechy - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest próbek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potęgi\n",
    "        \n",
    "        for kolumna in wybrane_cechy: #3 cechy\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odległości \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odległość\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z średniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 4] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano próbkę\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:4] = test_class[:, wybrane_cechy] #chce cechy\n",
    "#numpy tak naprawdę nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Lobedness','Elongation','Eccentricity',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          40           0          14           1           0\n",
      "True: 11.0          0          85           3           0           0\n",
      "True: 25.0          8           0          24           1           0\n",
      "True: 30.0          0           0          14          41           0\n",
      "True: 31.0          0           0           0           0          44\n",
      "\n",
      "\n",
      "Dokładność:  85.0909090909091 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + normalizacja + 5 wybranych cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Aspect Ratio</th>\n",
       "      <th>Isoperimetric Factor</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.744569</td>\n",
       "      <td>0.489485</td>\n",
       "      <td>0.878487</td>\n",
       "      <td>0.114205</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.071034</td>\n",
       "      <td>0.631097</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.888243</td>\n",
       "      <td>0.414745</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.550790</td>\n",
       "      <td>0.748358</td>\n",
       "      <td>0.025252</td>\n",
       "      <td>0.233860</td>\n",
       "      <td>0.131375</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.077102</td>\n",
       "      <td>0.675440</td>\n",
       "      <td>0.487136</td>\n",
       "      <td>0.886564</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.151979</td>\n",
       "      <td>0.168926</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.650511</td>\n",
       "      <td>0.703015</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.183214</td>\n",
       "      <td>0.706166</td>\n",
       "      <td>0.082252</td>\n",
       "      <td>0.539703</td>\n",
       "      <td>0.249261</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.229129</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.060216</td>\n",
       "      <td>0.542140</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.315646</td>\n",
       "      <td>0.034811</td>\n",
       "      <td>0.643095</td>\n",
       "      <td>0.655226</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.663956</td>\n",
       "      <td>0.887008</td>\n",
       "      <td>0.064020</td>\n",
       "      <td>0.355481</td>\n",
       "      <td>0.240784</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.108593</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.595283</td>\n",
       "      <td>0.657139</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Lobedness  Elongation  Eccentricity  Aspect Ratio  \\\n",
       "0     31.0   0.091549    0.744569      0.489485      0.878487   \n",
       "1     31.0   0.071034    0.631097      0.476341      0.888243   \n",
       "2     30.0   0.550790    0.748358      0.025252      0.233860   \n",
       "3     31.0   0.077102    0.675440      0.487136      0.886564   \n",
       "4     11.0   0.151979    0.168926      0.023431      0.650511   \n",
       "..     ...        ...         ...           ...           ...   \n",
       "270    5.0   0.183214    0.706166      0.082252      0.539703   \n",
       "271    5.0   0.229129    0.690647      0.060216      0.542140   \n",
       "272   11.0   0.121004    0.315646      0.034811      0.643095   \n",
       "273   25.0   0.663956    0.887008      0.064020      0.355481   \n",
       "274   11.0   0.108593    0.035960      0.021973      0.595283   \n",
       "\n",
       "     Isoperimetric Factor  Klasyfikacja probki  \n",
       "0                0.114205                  5.0  \n",
       "1                0.414745                 31.0  \n",
       "2                0.131375                 30.0  \n",
       "3                0.255600                 31.0  \n",
       "4                0.703015                 11.0  \n",
       "..                    ...                  ...  \n",
       "270              0.249261                  5.0  \n",
       "271              0.213592                  5.0  \n",
       "272              0.655226                 11.0  \n",
       "273              0.240784                 25.0  \n",
       "274              0.657139                 11.0  \n",
       "\n",
       "[275 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns_name = ['Class','Specimen Number','Eccentricity','Aspect Ratio','Elongation','Solidity',\n",
    "#                'Stochastic Convexity','Isoperimetric Factor','Maximal Indentation Depth','Lobedness',\n",
    "#                'Average Intensity','Average Contrast','Smoothness','Third moment','Uniformity','Entropy']\n",
    "\n",
    "#wybrane cechy z powyzej, narazie top3\n",
    "wybrane_cechy = [10,5,3,4,8] #Aspect Ratio, S\n",
    "\n",
    "#Wybieranie klas\n",
    "train_normalized_df = pd.DataFrame(train_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_normalized_df.loc[train_normalized_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_normalized_df = pd.DataFrame(test_normalized, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_normalized_df.loc[test_normalized_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie średniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyjść numer klasy\n",
    "\n",
    "#Liczenie odległości\n",
    "sum_pow = 0 #init zmiennej do liczenia potęgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = która klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],7)) #tyle ile probek test. wierszy, 5 bo: klasa - 5 cech - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest próbek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potęgi\n",
    "        \n",
    "        for kolumna in wybrane_cechy: #3 cechy\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odległości \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odległość\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z średniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 6] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano próbkę\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:6] = test_class[:, wybrane_cechy] #chce cechy\n",
    "#numpy tak naprawdę nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Lobedness','Elongation','Eccentricity','Aspect Ratio','Isoperimetric Factor',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          54           0           1           0           0\n",
      "True: 11.0          0          88           0           0           0\n",
      "True: 25.0          0           0          33           0           0\n",
      "True: 30.0          0           0          15          40           0\n",
      "True: 31.0          8           0           0           0          36\n",
      "\n",
      "\n",
      "Dokładność:  91.27272727272727 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorytm NM (Euklides) + brak normalizacji + 3 wybrane cechy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Lobedness</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Aspect Ratio</th>\n",
       "      <th>Isoperimetric Factor</th>\n",
       "      <th>Klasyfikacja probki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.933460</td>\n",
       "      <td>9.735100</td>\n",
       "      <td>0.904440</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.849910</td>\n",
       "      <td>9.491200</td>\n",
       "      <td>0.913970</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>1.120800</td>\n",
       "      <td>0.274730</td>\n",
       "      <td>0.024394</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.013721</td>\n",
       "      <td>0.882560</td>\n",
       "      <td>9.691500</td>\n",
       "      <td>0.912330</td>\n",
       "      <td>0.049695</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.028638</td>\n",
       "      <td>0.509610</td>\n",
       "      <td>1.087000</td>\n",
       "      <td>0.681740</td>\n",
       "      <td>0.140820</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.905184</td>\n",
       "      <td>2.178478</td>\n",
       "      <td>0.573496</td>\n",
       "      <td>0.048404</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.044008</td>\n",
       "      <td>0.893757</td>\n",
       "      <td>1.769592</td>\n",
       "      <td>0.575877</td>\n",
       "      <td>0.041139</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>0.617641</td>\n",
       "      <td>1.298175</td>\n",
       "      <td>0.674496</td>\n",
       "      <td>0.131087</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.130635</td>\n",
       "      <td>1.038339</td>\n",
       "      <td>1.840179</td>\n",
       "      <td>0.393537</td>\n",
       "      <td>0.046677</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>0.411706</td>\n",
       "      <td>1.059946</td>\n",
       "      <td>0.627790</td>\n",
       "      <td>0.131477</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Lobedness  Elongation  Eccentricity  Aspect Ratio  \\\n",
       "0     31.0   0.016599    0.933460      9.735100      0.904440   \n",
       "1     31.0   0.012512    0.849910      9.491200      0.913970   \n",
       "2     30.0   0.108090    0.936250      1.120800      0.274730   \n",
       "3     31.0   0.013721    0.882560      9.691500      0.912330   \n",
       "4     11.0   0.028638    0.509610      1.087000      0.681740   \n",
       "..     ...        ...         ...           ...           ...   \n",
       "270    5.0   0.034861    0.905184      2.178478      0.573496   \n",
       "271    5.0   0.044008    0.893757      1.769592      0.575877   \n",
       "272   11.0   0.022467    0.617641      1.298175      0.674496   \n",
       "273   25.0   0.130635    1.038339      1.840179      0.393537   \n",
       "274   11.0   0.019995    0.411706      1.059946      0.627790   \n",
       "\n",
       "     Isoperimetric Factor  Klasyfikacja probki  \n",
       "0                0.020897                 31.0  \n",
       "1                0.082108                 31.0  \n",
       "2                0.024394                 30.0  \n",
       "3                0.049695                 31.0  \n",
       "4                0.140820                 11.0  \n",
       "..                    ...                  ...  \n",
       "270              0.048404                  5.0  \n",
       "271              0.041139                  5.0  \n",
       "272              0.131087                 11.0  \n",
       "273              0.046677                  5.0  \n",
       "274              0.131477                 11.0  \n",
       "\n",
       "[275 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wybieranie klas\n",
    "train_df = pd.DataFrame(train, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "train_class = train_df.loc[train_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "train_class = train_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "test_df = pd.DataFrame(test, columns = columns_name) #DataFrame 'pomocniczy'\n",
    "test_class = test_df.loc[test_df['Class'].isin(klasy)] #by wybrać klasy\n",
    "test_class = test_class.to_numpy() #z powrotem do numpy arraya\n",
    "\n",
    "#Liczenie średniej\n",
    "mean = np.empty((len(klasy), np.shape(train_class)[1]))  #ile-klas, ile-kolumn-w-klasie [5, 16], [wiersze, kolumny]\n",
    "mean_wiersz = 0\n",
    "\n",
    "for y in klasy: #tyle, ile jest klas\n",
    "    mean[mean_wiersz,:] = np.mean(train_class[(train_class[:,0] == y), :], axis = 0)\n",
    "    mean_wiersz += 1\n",
    "    #do wiersza przypisz all kolumny z liczenia sredniej (po all kolumnach)\n",
    "    #z train_class[wszystkie wiersze, gdzie klasa sie zgadza, all kolumny]\n",
    "    #w pierwszej kolumnie musi wyjść numer klasy\n",
    "\n",
    "#Liczenie odległości\n",
    "sum_pow = 0 #init zmiennej do liczenia potęgi\n",
    "odleglosc = np.empty((5,2)) #5 wierszy, 2 kolumny - wiersze = klasy; kolumna1 = sqrt(odleglosc); kolumna2 = która klasa\n",
    "klasyfikacja = np.empty((np.shape(test_class)[0],7)) #tyle ile probek test. wierszy, 5 bo: klasa - 5 cech - klasyfikacja\n",
    "\n",
    "for probka_wiersz in range(np.shape(test_class)[0]): #tyle, ile jest próbek testowych\n",
    "    \n",
    "    for klasa in range(len(klasy)): #tyle, ile jest klas\n",
    "        sum_pow = 0 #reset policzonej potęgi\n",
    "        \n",
    "        for kolumna in wybrane_cechy: #3 cechy\n",
    "            sum_pow += (test_class[probka_wiersz, kolumna] - mean[klasa, kolumna]) ** 2 #liczenie odległości \n",
    "        \n",
    "        odleglosc[klasa,0] = np.sqrt(sum_pow) #do wiersza 0 / 1 / ...  i kolumny 0 przypisz odległość\n",
    "        odleglosc[klasa,1] = mean[klasa,0] #do wiersza 0 / 1 / ... i kolumny 1 przypisz jaka to jest klasa (policzona z średniej defacto)\n",
    "    \n",
    "    wynik = np.argmin(odleglosc, axis = 0) #wynik = posortuj od najmniejszej do najwiekszej po kolumnach\n",
    "    klasyfikacja[probka_wiersz, 6] = odleglosc[wynik[0], 1] #jako ostatnia kolumna chcemy info, do ktorej klasy przypisano próbkę\n",
    "\n",
    "klasyfikacja[:, 0]  = test_class[:, 0] #chce klasy\n",
    "klasyfikacja[:, 1:6] = test_class[:, wybrane_cechy] #chce cechy\n",
    "#numpy tak naprawdę nie bierze od 1 do 11, tylko od 1 do 10\n",
    "columns_name_nm = ['Class',\n",
    "                   'Lobedness','Elongation','Eccentricity','Aspect Ratio','Isoperimetric Factor',\n",
    "                   'Klasyfikacja probki']\n",
    "wynik_klasyfikacji = pd.DataFrame(klasyfikacja, columns = columns_name_nm)\n",
    "wynik_klasyfikacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Pred: 5.0  Pred: 11.0  Pred: 25.0  Pred: 30.0  Pred: 31.0\n",
      "True: 5.0          42           1          12           0           0\n",
      "True: 11.0          0          86           2           0           0\n",
      "True: 25.0          7           0          25           1           0\n",
      "True: 30.0          0           0          10          45           0\n",
      "True: 31.0          0           0           0           0          44\n",
      "\n",
      "\n",
      "Dokładność:  88.0 %\n"
     ]
    }
   ],
   "source": [
    "Matrix()\n",
    "Dokladnosc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wnioski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://matplotlib.org/stable/gallery/lines_bars_and_markers/barchart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['NM 10 cech','NM 3 cechy Fisher','NM 5 cech Fisher']\n",
    "znormalizowane = [82.18,84,91.27]\n",
    "nie_znormalizowane = [74.55,85.09,88]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, znormalizowane, width, label='Znormalizowane dane')\n",
    "rects2 = ax.bar(x + width/2, nie_znormalizowane, width, label='Nieznormalizowane dane')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Dokładność %')\n",
    "ax.set_title('Klasyfikacja wyniki')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NM 10 cech:\n",
    "- 82.18% po normalizacji\n",
    "- 74.55% przed normalizacją\n",
    "\n",
    "NM 3 cechy Fisher:\n",
    "- 84% po normalizacji\n",
    "- 85.09% przed normalizacją\n",
    "\n",
    "NM 5 cech Fisher:\n",
    "- 91.27% po normalizacji\n",
    "- 88% przed normalizacją"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak można zauważyć, nie zawsze wybrane losowo cechy będą lepsze od dobrze wybranych (za pomocą Fishera). Wykorzystanie zaledwie 3 cech, lecz dobrych (zamiast 10) pozwoliło na zwiększenie skuteczności algorytmu NM o 2% po oraz ok. 10% przed normalizacją.\n",
    "\n",
    "Im więcej dobrze dobranych cech, tj. 5 cech Fisher, tym osiągamy najwyższy w tym ćwiczeniu procent klasyfikacji, tj. 91.27% po oraz 88% przed normalizacją danych.\n",
    "\n",
    "Dobrze dobrane cechy pozwoliły nieznormalizowanym danym na dużo bardziej zbliżone wyniki do znormalizowanych."
   ]
  }
 ],
 "metadata": {
  "author": {
   "emails": [
    "rsusik@kis.p.lodz.pl"
   ],
   "name": "Robert Susik"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
